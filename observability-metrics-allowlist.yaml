apiVersion: v1
data:
  metrics_list.yaml: |
    collect_rules:
      - annotations:
          description: >
            By default, a SNO cluster does not collect pod and
            container resource metrics. Once a SNO
            cluster  reaches a level of resource consumption,
            these granular metrics are collected
            dynamically.  When the cluster resource consumption
            is consistently less than the threshold for a period
            of time,  collection of the granular metrics stops.
        group: SNOResourceUsage
        rules:
          - annotations:
              description: >
                Collects the dynamic metrics specified if the
                cluster cpu usage is constantly more than 70%
                for 2 minutes
            collect: SNOHighCPUUsage
            dynamic_metrics:
              matches: []
              names:
                - container_cpu_cfs_periods_total
                - container_cpu_cfs_throttled_periods_total
                - kube_pod_container_resource_limits
                - kube_pod_container_resource_requests
                - namespace_workload_pod:kube_pod_owner:relabel
                - node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate
                - node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
            expr: (1 - avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m]))) * 100 > 70
            for: 2m
          - annotations:
              description: >
                Collects the dynamic metrics specified if the
                cluster memory usage is constantly more than 70%
                for 2 minutes
            collect: SNOHighMemoryUsage
            dynamic_metrics:
              matches:
                - __name__="container_memory_cache",container!=""
                - __name__="container_memory_rss",container!=""
                - __name__="container_memory_swap",container!=""
                - __name__="container_memory_working_set_bytes",container!=""
              names:
                - kube_pod_container_resource_limits
                - kube_pod_container_resource_requests
                - namespace_workload_pod:kube_pod_owner:relabel
            expr: (1 - sum(:node_memory_MemAvailable_bytes:sum) /
              sum(kube_node_status_allocatable{resource=\"memory\"}))
              * 100 > 70
            for: 2m
        selector:
          matchExpressions:
            - key: clusterType
              operator: In
              values:
              - SNO
    matches:
      - __name__="workqueue_queue_duration_seconds_bucket",job="apiserver"
      - __name__="workqueue_adds_total",job="apiserver"
      - __name__="workqueue_depth",job="apiserver"
      - __name__="go_goroutines",job="apiserver"
      - __name__="process_cpu_seconds_total",job="apiserver"
      - __name__="process_resident_memory_bytes",job="apiserver"
      - __name__="container_memory_cache",container!=""
      - __name__="container_memory_rss",container!=""
      - __name__="container_memory_swap",container!=""
      - __name__="container_memory_working_set_bytes",container!=""
    names:
      - :node_memory_MemAvailable_bytes:sum
      - ALERTS
      - authenticated_user_requests
      - authentication_attempts
      - assisted_installer_cluster_creations
      - assisted_installer_cluster_installation_started
      - assisted_installer_cluster_installation_second
      - assisted_installer_cluster_host_installation_count
      - assisted_installer_host_installation_phase_seconds
      - assisted_installer_cluster_host_disk_sync_duration_ms
      - assisted_installer_cluster_host_image_pull_status
      - assisted_installer_filesystem_usage_percentage
      - cluster:capacity_cpu_cores:sum
      - cluster:capacity_memory_bytes:sum
      - cluster:container_cpu_usage:ratio
      - cluster:container_spec_cpu_shares:ratio
      - cluster:cpu_usage_cores:sum
      - cluster:memory_usage:ratio
      - cluster:memory_usage_bytes:sum
      - cluster:usage:resources:sum
      - cluster_infrastructure_provider
      - cluster_version
      - cluster_version_payload
      - container_cpu_cfs_periods_total
      - container_cpu_cfs_throttled_periods_total
      - container_spec_cpu_quota
      - coredns_dns_request_count_total
      - coredns_dns_request_duration_seconds_sum
      - coredns_dns_request_type_count_total
      - coredns_dns_response_rcode_count_total
      - etcd_debugging_mvcc_db_total_size_in_bytes
      - etcd_mvcc_db_total_size_in_bytes
      - etcd_debugging_snap_save_total_duration_seconds_sum
      - etcd_disk_backend_commit_duration_seconds_bucket
      - etcd_disk_backend_commit_duration_seconds_sum
      - etcd_disk_wal_fsync_duration_seconds_bucket
      - etcd_disk_wal_fsync_duration_seconds_sum
      - etcd_object_counts
      - etcd_network_client_grpc_received_bytes_total
      - etcd_network_client_grpc_sent_bytes_total
      - etcd_network_peer_received_bytes_total
      - etcd_network_peer_sent_bytes_total
      - etcd_server_client_requests_total
      - etcd_server_has_leader
      - etcd_server_health_failures
      - etcd_server_leader_changes_seen_total
      - etcd_server_proposals_failed_total
      - etcd_server_proposals_pending
      - etcd_server_proposals_committed_total
      - etcd_server_proposals_applied_total
      - etcd_server_quota_backend_bytes
      - grpc_server_started_total
      - haproxy_backend_connection_errors_total
      - haproxy_backend_connections_total
      - haproxy_backend_current_queue
      - haproxy_backend_http_average_response_latency_milliseconds
      - haproxy_backend_max_sessions
      - haproxy_backend_response_errors_total
      - haproxy_backend_up
      - http_requests_total
      - instance:node_filesystem_usage:sum
      - instance:node_cpu_utilisation:rate1m
      - instance:node_load1_per_cpu:ratio
      - instance:node_memory_utilisation:ratio
      - instance:node_network_receive_bytes_excluding_lo:rate1m
      - instance:node_network_receive_drop_excluding_lo:rate1m
      - instance:node_network_transmit_bytes_excluding_lo:rate1m
      - instance:node_network_transmit_drop_excluding_lo:rate1m
      - instance:node_num_cpu:sum
      - instance:node_vmstat_pgmajfault:rate1m
      - instance_device:node_disk_io_time_seconds:rate1m
      - instance_device:node_disk_io_time_weighted_seconds:rate1m
      - kube_daemonset_status_desired_number_scheduled
      - kube_daemonset_status_number_unavailable
      - kube_node_spec_unschedulable
      - kube_node_status_allocatable
      - kube_node_status_allocatable_cpu_cores
      - kube_node_status_allocatable_memory_bytes
      - kube_node_status_capacity
      - kube_node_status_capacity_pods
      - kube_node_status_capacity_cpu_cores
      - kube_node_status_condition
      - kube_pod_container_resource_limits
      - kube_pod_container_resource_limits_cpu_cores
      - kube_pod_container_resource_limits_memory_bytes
      - kube_pod_container_resource_requests
      - kube_pod_container_resource_requests_cpu_cores
      - kube_pod_container_resource_requests_memory_bytes
      - kube_pod_info
      - kube_pod_owner
      - kube_resourcequota
      - kubelet_running_container_count
      - kubelet_runtime_operations
      - kubelet_runtime_operations_latency_microseconds
      - kubelet_volume_stats_available_bytes
      - kubelet_volume_stats_capacity_bytes
      - kube_persistentvolume_status_phase
      - machine_cpu_cores
      - machine_memory_bytes
      - mixin_pod_workload
      - namespace:kube_pod_container_resource_requests_cpu_cores:sum
      - namespace:kube_pod_container_resource_requests_memory_bytes:sum
      - namespace:container_memory_usage_bytes:sum
      - namespace_cpu:kube_pod_container_resource_requests:sum
      - namespace_workload_pod:kube_pod_owner:relabel
      - node_cpu_seconds_total
      - node_filesystem_avail_bytes
      - node_filesystem_free_bytes
      - node_filesystem_size_bytes
      - node_memory_MemAvailable_bytes
      - node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
      - node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate
      - node_netstat_Tcp_OutSegs
      - node_netstat_Tcp_RetransSegs
      - node_netstat_TcpExt_TCPSynRetrans
      - policyreport_info
      - up
      - cluster_monitoring_operator_reconcile_errors_total
      - cluster_monitoring_operator_reconcile_attempts_total
      - cluster_operator_conditions
      - cluster_operator_up
      - cluster:policy_governance_info:propagated_count
      - cluster:policy_governance_info:propagated_noncompliant_count
      - policy:policy_governance_info:propagated_count
      - policy:policy_governance_info:propagated_noncompliant_count
    recording_rules:
      - expr: histogram_quantile(0.99,sum(rate(apiserver_request_duration_seconds_bucket{job=\"apiserver\",
          verb!=\"WATCH\"}[5m])) by (le))
        record: apiserver_request_duration_seconds:histogram_quantile_99
      - expr: histogram_quantile(0.99,
          sum(rate(apiserver_request_duration_seconds_bucket{job=\"apiserver\",
          verb!=\"WATCH\"}[5m])) by (le, verb, instance))
        record: apiserver_request_duration_seconds:histogram_quantile_99:instance
      - expr: sum(rate(apiserver_request_total{job=\"apiserver\"}[1h])) by(code,
          instance)
        record: sum:apiserver_request_total:1h
      - expr: sum(rate(apiserver_request_total{job=\"apiserver\"}[5m])) by(code,
          instance)
        record: sum:apiserver_request_total:5m
      - expr: sum(rate(grpc_server_handled_total{job=\"etcd\",grpc_type=\"unary\",grpc_code!=\"OK\"}[5m]))
        record: rpc_rate:grpc_server_handled_total:sum_rate
      - expr: sum(grpc_server_started_total{job=\"etcd\",grpc_service=\"etcdserverpb.Watch\",grpc_type=\"bidi_stream\"})
          -
          sum(grpc_server_handled_total{job=\"etcd\",grpc_service=\"etcdserverpb.Watch\",grpc_type=\"bidi_stream\"})
        record: active_streams_watch:grpc_server_handled_total:sum
      - expr: sum(grpc_server_started_total{job=\"etcd\",grpc_service=\"etcdserverpb.Lease\",grpc_type=\"bidi_stream\"})
          -
          sum(grpc_server_handled_total{job=\"etcd\",grpc_service=\"etcdserverpb.Lease\",grpc_type=\"bidi_stream\"})
        record: active_streams_lease:grpc_server_handled_total:sum
      - expr: sum(sum(sum(kube_pod_container_resource_requests{resource=\"cpu\"}) by
          (pod,namespace,container) * on(pod,namespace)
          group_left(phase)
          max(kube_pod_status_phase{phase=~\"Running|Pending|Unknown\"}
          >0) by (pod,namespace,phase)) by
          (pod,namespace,phase))
        record: cluster:kube_pod_container_resource_requests:cpu:sum
      - expr: sum(sum(sum(kube_pod_container_resource_requests{resource=\"memory\"}) by
          (pod,namespace,container) * on(pod,namespace)
          group_left(phase)
          max(kube_pod_status_phase{phase=~\"Running|Pending|Unknown\"}
          >0) by (pod,namespace,phase)) by
          (pod,namespace,phase))
        record: cluster:kube_pod_container_resource_requests:memory:sum
      - expr: sum(increase(apiserver_request_duration_seconds_bucket{job=\"apiserver\",service=\"kubernetes\",le=\"1\",verb=~\"POST|PUT|DELETE|PATCH\"}[1m]))
          /
          sum(increase(apiserver_request_duration_seconds_count{job=\"apiserver\",service=\"kubernetes\",verb=~\"POST|PUT|DELETE|PATCH\"}[1m]))
        record: sli:apiserver_request_duration_seconds:trend:1m
      - expr: sum(container_memory_rss) by (container, namespace)
        record: container_memory_rss:sum
      - expr: sum(kube_pod_container_resource_limits) by (resource, namespace)
        record: kube_pod_container_resource_limits:sum
      - expr: sum(kube_pod_container_resource_requests{container!=\"\"}) by (resource,
          namespace)
        record: kube_pod_container_resource_requests:sum
      - expr: count(avg(namespace_workload_pod:kube_pod_owner:relabel{pod!=\"\"}) by
          (workload, namespace)) by (namespace)
        record: namespace_workload_pod:kube_pod_owner:relabel:avg
      - expr: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{container!=\"\"})
          by (namespace) or
          sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate{container!=\"\"})
          by (namespace)
        record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum
    renames:
      etcd_mvcc_db_total_size_in_bytes: etcd_debugging_mvcc_db_total_size_in_bytes
      mixin_pod_workload: namespace_workload_pod:kube_pod_owner:relabel
      namespace:kube_pod_container_resource_requests_cpu_cores:sum: namespace_cpu:kube_pod_container_resource_requests:sum
      node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate:
        node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
    rules: []
kind: ConfigMap
metadata:
  name: observability-metrics-allowlist
  namespace: cstarktest
